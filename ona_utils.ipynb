{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy import NaN, Inf, arange, isscalar, asarray, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_RATIO = 0.75\n",
    "MIN_MATCH_COUNT = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakdet(v, delta, x=None):\n",
    "    \"\"\"\n",
    "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
    "\n",
    "    Returns two arrays\n",
    "\n",
    "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
    "    %PEAKDET Detect peaks in a vector\n",
    "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
    "    %        maxima and minima (\"peaks\") in the vector V.\n",
    "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
    "    %        contains indices in V, and column 2 the found values.\n",
    "    %      \n",
    "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
    "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
    "    %        X-values.\n",
    "    %\n",
    "    %        A point is considered a maximum peak if it has the maximal\n",
    "    %        value, and was preceded (to the left) by a value lower by\n",
    "    %        DELTA.\n",
    "\n",
    "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
    "    % This function is released to the public domain; Any use is allowed.\n",
    "\n",
    "    \"\"\"\n",
    "    maxtab = []\n",
    "    mintab = []\n",
    "\n",
    "    if x is None:\n",
    "        x = arange(len(v))\n",
    "\n",
    "    v = asarray(v)\n",
    "\n",
    "    if len(v) != len(x):\n",
    "        sys.exit('Input vectors v and x must have same length')\n",
    "\n",
    "    if len(v) < 1:\n",
    "        sys.exit('Array must have at least 1 element')\n",
    "\n",
    "    if not isscalar(delta):\n",
    "        sys.exit('Input argument delta must be a scalar')\n",
    "\n",
    "    if delta <= 0:\n",
    "        sys.exit('Input argument delta must be positive')\n",
    "\n",
    "    mn, mx = v[0], v[0]\n",
    "    mnpos, mxpos = None, None\n",
    "\n",
    "    lookformax = True\n",
    "    maxWidth = 0\n",
    "    minWidth = 0\n",
    "\n",
    "    for i in arange(1, len(v)):\n",
    "        this = v[i]\n",
    "        if this > mx:\n",
    "            mx = this\n",
    "            mxpos = x[i]\n",
    "            maxWidth += 1\n",
    "        if this < mn:\n",
    "            mn = this\n",
    "            mnpos = x[i]\n",
    "            minWidth += 1\n",
    "\n",
    "        if lookformax:\n",
    "            if this < mx-delta:\n",
    "                if mxpos != None:\n",
    "                    \"\"\"\n",
    "                        TODO: width here might not be really accurate if there is a \n",
    "                        sharp increase from the left, and then a slower drop to the right,\n",
    "                        the width will still be really small. We need a way to get the width from both \n",
    "                        sides of the peak\n",
    "                    \"\"\"\n",
    "                    maxtab.append(\n",
    "                        (mxpos, mx, findPeakWidth(mxpos, v, mx, findMax=True)))\n",
    "                mn = this\n",
    "                maxWidth = 0\n",
    "                mnpos = x[i]\n",
    "                lookformax = False\n",
    "        else:\n",
    "            if this > mn+delta:\n",
    "                if mnpos != None:\n",
    "                    mintab.append(\n",
    "                        (mnpos, mn, findPeakWidth(mnpos, v, mn, findMax=False)))\n",
    "                mx = this\n",
    "                minWidth = 0\n",
    "                mxpos = x[i]\n",
    "                lookformax = True\n",
    "\n",
    "    return array(maxtab), array(mintab)\n",
    "\n",
    "\n",
    "def findPeakWidth(idx, arr, val, findMax):\n",
    "    width = 0\n",
    "    if (findMax):\n",
    "        # Find the furthest minimum left\n",
    "        i = idx - 1\n",
    "        # print(arr[i - 10: i + 10])\n",
    "        # print(arr[i])\n",
    "        while (i > 0 and arr[i] > arr[i - 1]):\n",
    "            width += 1\n",
    "            i -= 1\n",
    "        # print('First', i, width)\n",
    "        # Find the furthest minimum right\n",
    "        i = idx\n",
    "        while (i < len(arr) - 1 and arr[i] > arr[i + 1]):\n",
    "            width += 1\n",
    "            i += 1\n",
    "        # print('Sec', i, width)\n",
    "    else:\n",
    "        # Find the furthest maximum left\n",
    "        i = idx\n",
    "        while (i > 0 and arr[i] < arr[i - 1]):\n",
    "            width += 1\n",
    "            i -= 1\n",
    "        # Find the furthest maximum right\n",
    "        i = idx\n",
    "        while (i < len(arr) - 1 and arr[i] < arr[i + 1]):\n",
    "            width += 1\n",
    "            i += 1\n",
    "    return width\n",
    "\n",
    "def calculateRedColorPercentage(img):\n",
    "    print('[INFO] detectRedColor()')\n",
    "#     hsv = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    # Red color range\n",
    "    RED_COLOR_LOW_HUE_LOWER = np.array(\n",
    "        [0, 100, 100]\n",
    "    )\n",
    "\n",
    "    RED_COLOR_LOW_HUE_UPPER = np.array([10, 255, 255])\n",
    "    RED_COLOR_HIGH_HUE_LOWER = np.array([160, 150, 100])\n",
    "    RED_COLOR_HIGH_HUE_UPPER = np.array([179, 255, 255])\n",
    "    \n",
    "    lower_red_threshold = cv2.inRange(hsv, RED_COLOR_LOW_HUE_LOWER, RED_COLOR_LOW_HUE_UPPER)\n",
    "    upper_red_threshold = cv2.inRange(hsv, RED_COLOR_HIGH_HUE_LOWER, RED_COLOR_HIGH_HUE_UPPER)\n",
    "\n",
    "    red_threshold = cv2.addWeighted(lower_red_threshold, 1.0, upper_red_threshold, 1.0, gamma=0.0)\n",
    "    plt.imshow(red_threshold)\n",
    "    plt.show()\n",
    "    red_color_percentage = cv2.countNonZero(red_threshold) / (red_threshold.shape[0] * red_threshold.shape[1])\n",
    "\n",
    "    return red_color_percentage\n",
    "\n",
    "def detectBlood(img, blood_threshold=0.25):\n",
    "    print('[INFO] detectBlood()')\n",
    "    red_color_percentage = self.calculateRedColorPercentage(img)\n",
    "    return red_color_percentage > blood_threshold\n",
    "\n",
    "def checkGlare(img):\n",
    "    print(\"[INFO] check glare\")\n",
    "    hist_full = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    maxWhite = 0\n",
    "    clipCount = 0\n",
    "    for i, h in enumerate(hist_full):\n",
    "        if h > 0:\n",
    "            maxWhite = i\n",
    "        \n",
    "        if i == len(hist_full) - 1:\n",
    "            clipCount = h\n",
    "            \n",
    "    print(\"maxWhite\", maxWhite, \"clipCount\", clipCount)\n",
    "    \n",
    "    return clipCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, rdt_type, rotated=False):\n",
    "        config = json.load(open('configs/config.json'))\n",
    "        \n",
    "        self.rdt_type = rdt_type\n",
    "        self.config = config[rdt_type]\n",
    "        self.ref_img = cv2.imread('configs/%s.jpg'%self.config['REF_IMG'], 0)\n",
    "        if rdt_type == 'experimental':\n",
    "            self.ref_img_size = (216, 740)\n",
    "        \n",
    "        if rotated:\n",
    "            self.ref_img = cv2.rotate(self.ref_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            if rdt_type == 'experimental':\n",
    "                self.ref_img_size = (740, 216)\n",
    "            \n",
    "        self.sift_detector = cv2.xfeatures2d.SIFT_create()\n",
    "        self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "        ref_keypoints, ref_descriptors = self.sift_detector.detectAndCompute(\n",
    "            self.ref_img, None)\n",
    "        self.ref_keypoints = ref_keypoints \n",
    "        self.ref_descriptors = ref_descriptors\n",
    "        \n",
    "    def detectRDT(self, img, cnt=5):\n",
    "        height, width, channel = img.shape\n",
    "        p1 = (0, int(height * (1 - (self.config['VIEW_FINDER_SCALE_W']) / CROP_RATIO) / 2))\n",
    "        p2 = (int(width - p1[0]), int(height - p1[1]))\n",
    "        roi = img[p1[1]:p2[1], p1[0]:p2[0]]\n",
    "        \n",
    "        # img = roi\n",
    "        # mask = np.zeros((height, width), np.uint8)\n",
    "        # mask[p1[1]:p2[1], p1[0]: p2[0]] = 255\n",
    "        keypoints, descriptors = self.sift_detector.detectAndCompute(img, None)\n",
    "        \n",
    "        \n",
    "        # Matching\n",
    "        if descriptors is None: \n",
    "            return None\n",
    "        matches = self.matcher.knnMatch(self.ref_descriptors, descriptors, k=2)\n",
    "        print('[INFO] Finish matching')\n",
    "        # print('matches', matches)\n",
    "        # Apply ratio test\n",
    "        good = []\n",
    "        if matches is None or len(matches) == 0 or len(matches[0]) < 2:\n",
    "            return None\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.80*n.distance:\n",
    "                good.append(m)\n",
    "\n",
    "\n",
    "        #matchingImage = cv2.drawMatches(self.ref_img, self.ref_keypoints, img,\n",
    "        #                               keypoints, good, None, flags=2)\n",
    "        #matchingImage = cv2.cvtColor(matchingImage, cv2.COLOR_BGR2RGB)\n",
    "        #plt.imshow(matchingImage)\n",
    "        # plt.title('SIFT Brute Force matching')\n",
    "        #plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "        #plt.show()\n",
    "\n",
    "        sum = 0\n",
    "        distance = 0\n",
    "        count = 0\n",
    "\n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        img2 = None\n",
    "        dst = None\n",
    "        print('[INFO] matches')\n",
    "\n",
    "        if len(good)> MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([ self.ref_keypoints[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ keypoints[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            # print('src_pts', src_pts)\n",
    "            # print('dst_pst', dst_pts)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, cnt)\n",
    "            print('[INFO] Finish finding Homography')\n",
    "            # print('[INFO] M Matrix', M)\n",
    "            # print('[INFO] mask', mask)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            h,w = self.ref_img.shape\n",
    "            pts = np.float32([ [0,0],[w-1,0],[w-1,h-1],[0,h-1] ]).reshape(-1,1,2)\n",
    "            if M is None or M.size == 0:\n",
    "                return None\n",
    "            dst = cv2.perspectiveTransform(pts,M)\n",
    "            # print('[INFO] dst transformation pts', dst)\n",
    "            #img2 = np.copy(img)\n",
    "            #img2 = cv2.polylines(img2,[np.int32(dst)],True,(255,0,0))\n",
    "            #pts_box = cv2.minAreaRect(dst)\n",
    "            #box = cv2.boxPoints(pts_box) # cv2.boxPoints(rect) for OpenCV 3.x\n",
    "            #box = np.int0(box)\n",
    "            #cv2.drawContours(img2,[box],0,(0,0,255),2)\n",
    "            #print('[INFO] finish perspective transform')\n",
    "            #print(box)\n",
    "            #show_image(roi)\n",
    "            #show_image(img2)\n",
    "\n",
    "        else:\n",
    "            print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "            matchesMask = None\n",
    "            return None\n",
    "\n",
    "        draw_params = dict(matchColor = (255,0,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "        #img3 = cv2.drawMatches(self.ref_img,self.ref_keypoints,img,keypoints,good,None,**draw_params)\n",
    "        #plt.imshow(img3)\n",
    "        #plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "        #plt.show()\n",
    "        # show_image(img3)\n",
    "\n",
    "        h, w  = self.ref_img.shape\n",
    "        #refBoundary = np.float32([ [0,0], [0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "        refBoundary = np.float32([ [0,0],[w-1,0],[w-1,h-1],[0,h-1] ]).reshape(-1,1,2)\n",
    "        # print('Refboundary', refBoundary)\n",
    "        # print('Boundary', dst)\n",
    "        M = cv2.getPerspectiveTransform(dst, refBoundary)\n",
    "        # print('M matrixxxx', M)\n",
    "        transformedImage = cv2.warpPerspective(img ,M, (self.ref_img.shape[1], self.ref_img.shape[0]))\n",
    "        if self.rdt_type == 'experimental':\n",
    "            transformedImage = cv2.resize(transformedImage, (self.ref_img_size[1], self.ref_img_size[0]))\n",
    "\n",
    "        # show_image(roi)\n",
    "        # show_image(transformedImage)\n",
    "        transformedImage = cv2.cvtColor(transformedImage, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(transformedImage)\n",
    "        plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "        plt.show()\n",
    "\n",
    "        return dst \n",
    "    \n",
    "    def interpretResult(self, img, boundary=None, enhanced=True):\n",
    "        offset = 0\n",
    "        \n",
    "        cnt = 0\n",
    "        while True:\n",
    "            print('offset', offset)\n",
    "            cropped_img = self.cropResultWindow(img, boundary, offset=offset)\n",
    "            \n",
    "            blood_percentage = calculateRedColorPercentage(cropped_img)\n",
    "\n",
    "            clip_count = 0\n",
    "            \n",
    "            if enhanced:\n",
    "                enhanced_img, clip_count = self.enhanceImage(cropped_img, (5, int(cropped_img.shape[1]/3)))\n",
    "            else:\n",
    "                enhanced_img = cropped_img\n",
    "\n",
    "            enhanced_img_plt = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            h, w, _ = enhanced_img_plt.shape\n",
    "            plt.imshow(enhanced_img_plt)\n",
    "            plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False) \n",
    "            plt.show()\n",
    "\n",
    "            # Detect line location\n",
    "            maxtab, numberOfLines, mintab = self.detectLinesWithPeak(enhanced_img)\n",
    "\n",
    "            hls = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HLS) \n",
    "            colLightness = np.mean(hls[:,:,1], axis=0)\n",
    "            colLightness = [255] - colLightness\n",
    "\n",
    "            maxtab_org = []\n",
    "            mintab_org = []\n",
    "            for t in maxtab:\n",
    "                maxtab_org.append([t[0], colLightness[int(t[0])], t[2]])\n",
    "\n",
    "            for t in mintab:\n",
    "                mintab_org.append([t[0], colLightness[int(t[0])], t[2]])\n",
    "\n",
    "            #print('Max Org', np.array(maxtab_org))\n",
    "            #print('Min Org', np.array(mintab_org))\n",
    "\n",
    "            results = self.detectLinesWithRelativeLocation(maxtab)\n",
    "            \n",
    "            break\n",
    "        \n",
    "        return results, blood_percentage, clip_count, maxtab, mintab, maxtab_org, mintab_org\n",
    "        \n",
    "    def enhanceImage(self, img, tile):\n",
    "        print('[INFO] enhanceImage', img.shape)\n",
    "        # show_image(img)\n",
    "        #result = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "        #img = cv2.GaussianBlur(img, (7,7), 0)\n",
    "        #img = cv2.bilateralFilter(img,10,150,150)\n",
    "        result = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "         # create a CLAHE object (Arguments are optional).\n",
    "        clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=tile)\n",
    "        channels = cv2.split(result)\n",
    "        #channels[1] = cv2.bilateralFilter(channels[1],10,75,75)\n",
    "        cv2.normalize(channels[1], channels[1], alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        cl1 = clahe.apply(channels[1])\n",
    "        channels[1] = cl1\n",
    "        result = cv2.merge(channels)\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_HLS2RGB)\n",
    "        \n",
    "        clip_count = checkGlare(cl1)\n",
    "        #result = cv2.cvtColor(result, cv2.RGB2RGBA)\n",
    "        # show_image(result)\n",
    "        return result, clip_count\n",
    "    \n",
    "    def cropResultWindow(self, img, boundary, offset=0):\n",
    "        print('[INFO] cropResultWindow')\n",
    "        # show_image(img)\n",
    "        # show_image(self.fluRefImg)\n",
    "        # print('Boundary shape', boundary.shape)\n",
    "        # print('Boundary' , boundary)\n",
    "        # print('Image shape', img.shape)\n",
    "        h, w = self.ref_img.shape\n",
    "        # img2 = cv2.polylines(img,[np.int32(boundary)],True,(255,0,0))\n",
    "        # show_image(img2)\n",
    "        #refBoundary = np.float32([ [0,0], [0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "        refBoundary = np.float32([ [0,0],[w-1,0],[w-1,h-1],[0,h-1] ]).reshape(-1,1,2)\n",
    "        # print('Refboundary', refBoundary)\n",
    "        # print('Boundary', boundary)\n",
    "        M = cv2.getPerspectiveTransform(boundary, refBoundary)\n",
    "        transformedImage = cv2.warpPerspective(img,M, (self.ref_img.shape[1], self.ref_img.shape[0]))\n",
    "        if self.rdt_type == 'experimental':\n",
    "            transformedImage = cv2.resize(transformedImage, (self.ref_img_size[1], self.ref_img_size[0]))\n",
    "        # show_image(transformedImage)\n",
    "        # TODO: this is where things went wrong, it cannot perform perspective transform\n",
    "\n",
    "        tl = Point(self.config['FIDUCIAL_TO_RESULT_WINDOW_OFFSET'] - self.config['RESULT_WINDOW_RECT_HEIGHT']/2.0 - offset, \n",
    "                   self.config['RESULT_WINDOW_RECT_WIDTH_PADDING'])\n",
    "        br = Point(self.config['FIDUCIAL_TO_RESULT_WINDOW_OFFSET'] + self.config['RESULT_WINDOW_RECT_HEIGHT']/2.0 - offset,\n",
    "                   transformedImage.shape[0] - self.config['RESULT_WINDOW_RECT_WIDTH_PADDING'])\n",
    "                   \n",
    "        if tl is None and br is None:\n",
    "            return None\n",
    "        # print('[INFO] tl, br', tl.x, tl.y, br.x, br.y)\n",
    "        cropResultWindow = transformedImage[int(tl.y): int(br.y), int(tl.x):int(br.x)]\n",
    "        # print('[INFO] shape', cropResultWindow.shape, transformedImage.shape, img.shape)\n",
    "        # show_image(cropResultWindow)\n",
    "        # if (cropResultWindow.shape[0] > 0 and cropResultWindow.shape[1] > 0):\n",
    "        #     cropResultWindow.reshape((RESULT_WINDOW_RECT_HEIGHT, self.fluRefImg.shape[0] - 2 * RESULT_WINDOW_RECT_WIDTH_PADDING))\n",
    "        #     show_image(transformedImage)\n",
    "        return cropResultWindow\n",
    "    \n",
    "    def detectLinesWithPeak(self, img):\n",
    "        #variables = {}\n",
    "        #with open('variables/variables.json') as json_file:\n",
    "        #    variables = json.load(json_file)\n",
    "        \n",
    "        print(img.shape)\n",
    "        # show_image(img)\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS) \n",
    "        # show_image(hls)\n",
    "        # hls1 = cv2.cvtColor(img, cv2.COLOR_RGB2HLS) \n",
    "        # show_image(hls1)\n",
    "        # HSL so only take the L channel to distinguish lines\n",
    "        # print('[INFO] result img shape', img.shape)\n",
    "        colR = np.mean(img[:,:,0], axis=0)\n",
    "        colG = np.mean(img[:,:,1], axis=0)\n",
    "        colB = np.mean(img[:,:,2], axis=0)\n",
    "\n",
    "        colLightness = np.mean(hls[:,:,1], axis=0)\n",
    "        colHue = np.mean(hls[:,:,0], axis=0)\n",
    "        colSaturation = np.mean(hls[:,:,2], axis=0)\n",
    "        # plt.plot(colLightness)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.plot(colHue)\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.plot(colSaturation)\n",
    "        # plt.show()\n",
    "        # print('[INFO] avgLightness shape', colLightness.shape)\n",
    "        # Inverse the L channel so that the lines will be detected as peak, not bottom like the original array\n",
    "        colLightness = [255] - colLightness\n",
    "        plt.figure(figsize=(5, 1.5))\n",
    "        plt.tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False) # labels along the bottom edge are off\n",
    "        plt.ylim(0, 255)\n",
    "        plt.ylabel(\"Lightness (L)\", fontsize=12)\n",
    "        plt.yticks([0, 255])\n",
    "        plt.plot(range(0, len(colLightness)), [255] - colLightness, '-o')\n",
    "        plt.show()\n",
    "        \n",
    "        #plt.figure(figsize=(5, 1.5))\n",
    "        #plt.tick_params(\n",
    "        #        axis='x',          # changes apply to the x-axis\n",
    "        #        which='both',      # both major and minor ticks are affected\n",
    "        #        bottom=False,      # ticks along the bottom edge are off\n",
    "        #        top=False,         # ticks along the top edge are off\n",
    "        #        labelbottom=False) # labels along the bottom edge are off\n",
    "        #plt.yticks([0, 180])\n",
    "        #plt.ylim(0, 180)\n",
    "        #plt.ylabel(\"Hue (H)\", fontsize=12)\n",
    "        #plt.plot(range(0, len(colHue)), colHue, '-o')\n",
    "        #plt.show()\n",
    "        # print('[INFO] lightness shape', colLightness.shape)\n",
    "        # Find peak and peak should correspond to lines\n",
    "        maxtab, mintab = peakdet(colLightness, self.config['CONTROL_INTENSITY_PEAK_THRESHOLD'])\n",
    "        print('Max', maxtab)\n",
    "        #print('Min', mintab)\n",
    "        #print('Min', mintab)\n",
    "        #print('Total strip count', len(maxtab))\n",
    "\n",
    "        return maxtab, len(maxtab), mintab\n",
    "    \n",
    "        \n",
    "    def detectLinesWithRelativeLocation(self, maxtab):\n",
    "        results = [False]*3\n",
    "        for col, val, width in maxtab:\n",
    "            if col > self.config['TOP_LINE_POSITION'] - self.config['LINE_SEARCH_WIDTH'] and col < self.config['TOP_LINE_POSITION'] + self.config['LINE_SEARCH_WIDTH']:\n",
    "                results[0] = True\n",
    "            if col > self.config['MIDDLE_LINE_POSITION'] - self.config['LINE_SEARCH_WIDTH'] and col < self.config['MIDDLE_LINE_POSITION'] + self.config['LINE_SEARCH_WIDTH']:\n",
    "                results[1] = True\n",
    "            if col > self.config['BOTTOM_LINE_POSITION'] - self.config['LINE_SEARCH_WIDTH'] and col < self.config['BOTTOM_LINE_POSITION'] + self.config['LINE_SEARCH_WIDTH']+10:\n",
    "                results[2] = True\n",
    "        return results\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
